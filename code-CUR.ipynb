{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import cv2\n","# import numpy as np\n","# import os \n","# print(os.getcwd())\n","\n","# # 添加高斯噪声\n","# def GaessNoisy(src, sigma):\n","#     NoiseImg = src.copy()\n","#     s = np.random.normal(0, 1, size=src.shape)*sigma\n","#     NoiseImg = np.add(NoiseImg, s)\n","#     NoiseImg.astype(dtype=np.uint8)\n","#     return NoiseImg\n","\n","\n","# def readImage2Data():\n","#     img = cv2.imread('data/rgb/1.png')\n","#     # 添加高斯噪声\n","#     noisyImage = GaessNoisy(img, 20)\n","#     # 添加椒盐噪声\n","#     # noisyImage = SaltAndPepper(img, 0.2)\n","#     img = img/255.0\n","#     noisyImage = noisyImage/255.0\n","#     cv2.imshow('i', img)\n","#     cv2.imshow('img', noisyImage)\n","#     cv2.waitKey()\n","#     cv2.imwrite('./data/noise/1.png', noisyImage*255, [int(cv2.IMWRITE_JPEG_QUALITY), 100])   # 保存图片\n","\n","\n","\n","# readImage2Data()\n","!pip install einops"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["a\n"]}],"source":["#本模块用于读取数据，生成加载器，相关参数设置如下：\n","\n","left_path='./data/rgb'\n","right_path='./data/noise'\n","split_ratio=0.8\n","\n","import random\n","import cv2\n","import mindspore.dataset as ds\n","import os\n","import numpy as np\n","import glob\n","\n","def load_data_path(left_path,right_path,split_ratio=0.03):\n","    #load data path\n","    left_images=os.listdir(left_path)\n","    right_images=os.listdir(right_path)\n","    left_images.sort()\n","    right_images.sort()\n","    left_images_path = sorted(glob.glob(left_path + \"/*.png\"))\n","    right_images_path = sorted(glob.glob(right_path + \"/*.png\"))\n","    #print(left_images)\n","    #print(right_images)\n","    #print(left_images)\n","    \n","    #left_images_path=[left_path+'/'+img for img in left_images ]\n","    #right_images_path=[right_path+'/'+img for img in right_images]\n","    \n","    #print(left_images_path[:10])\n","    #print(right_images_path[:10])\n","    \n","    #split data\n","    data_length=len(left_images_path)\n","    temp=[(l,r) for l,r in zip(left_images_path,right_images_path)]\n","    #print(temp[:10])  \n","    random.shuffle(temp)\n","    num_traindata=int(split_ratio*data_length)\n","    train_data_path=temp[0:num_traindata]\n","    #print(num_traindata)  638\n","    val_data_path=temp[num_traindata:]\n","    \n","    return train_data_path,val_data_path\n","\n","\n","            \n","class imgDataset():\n","    def __init__(self, tra):\n","        super(imgDataset, self).__init__()\n","        self.tra=tra\n","        \n","        #for data,label in enumerate(self.data_generator(self.tra)):\n","        #   self.imgs.append(data)\n","        #   self.labels.append(label)\n","        \n","    def __getitem__(self, index):\n","        \n","        return self.data_generator(self.tra[index])\n","\n","    def __len__(self):\n","        return len(self.tra)\n","    \n","    def data_generator(self,data_path,is_train=True):\n","        #input data_path:list of tuple with (left,right)\n","        #output  dataset generator\n","        #\n","        #print('******************reading data*****************')\n","        left_img=cv2.imread(data_path[0])\n","        right_img=cv2.imread(data_path[1])\n","        return [left_img, right_img]\n","        \n","    # def _centerImage_(self,img):\n","    #     img = img.astype(np.float32)\n","    #     return img\n","    # def _rotateImage_(self,img):\n","    #     (h, w) = img.shape[:2]\n","    #     center=(w/2-0.5,h/2-0.5)\n","    #     M = cv2.getRotationMatrix2D(center, 180, 1.0)\n","    #     rotated = cv2.warpAffine(img, M, (w, h))\n","    #     return rotated\n","        \n","    # def _getGeometryFeat_(self,img_shape):\n","    #     H = img_shape[0]\n","    #     W = img_shape[1]\n","    #     feat = np.zeros((H,W,2))\n","    #     for j in range(H):\n","    #         for i in range(W):\n","    #             feat[j,i,0]=np.min([j-0,H-1-j])/(H-1)*1.0            \n","    #             feat[j,i,1]=np.min([i-0,W-1-i])/(W-1)*1.0\n","    #     return feat\n","print('a')"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["#inputshape:(1,2,5,h,w)\n","#outputshape:(1,6,h,w)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["import mindspore as mds\n","import mindspore.nn as nn\n","import numpy as np\n","import mindspore.numpy as mdsnp\n","mds.context.set_context(device_target='Ascend',mode=mds.context.PYNATIVE_MODE)#  GRAPH_MODE"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["from einops import rearrange, repeat\n","\n","# import random\n","# import glob\n","# import os\n","# import cv2\n","import mindspore.dataset as ds\n","import mindspore as mds\n","import mindspore.nn as nn\n","import mindspore.numpy as mdsnp\n","from mindspore import Model\n","from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n","import numpy as np\n","\n","class CyclicShift(nn.Cell):\n","    def __init__(self, displacement):\n","        super().__init__()\n","        self.displacement = displacement\n","\n","    def construct(self, x):\n","        return nn.Roll(x, shifts=(self.displacement, self.displacement), dims=(1, 2))\n","\n","\n","class Residual(nn.Cell):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def construct(self, x, **kwargs):\n","        #print('before res:',x.shape)\n","        x1 = self.fn(x, **kwargs)\n","        #print('after res:' , x1.shape)\n","        x1 = x1.asnumpy()\n","        x1 = rearrange(x1, 'b h_n w_n (c p1 p2) ->b c (h_n p1) (w_n p2)', p1=1, p2=1)\n","        x1 = mds.Tensor(x1)\n","\n","        return x1 + x\n","\n","\n","class PreNorm(nn.Cell):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def construct(self, x, **kwargs):\n","        x = self.fn(x, **kwargs)\n","        shape1 = x.shape[1:]\n","        m = nn.LayerNorm(shape1)\n","        return m(x)\n","\n","\n","class Feedconstruct(nn.Cell):\n","    def __init__(self, dim, hidden_dim):\n","        super().__init__()\n","        self.net = nn.SequentialCell(\n","            [nn.Dense(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dense(hidden_dim, dim)]\n","        )\n","\n","    def construct(self, x):\n","        x = rearrange(x, 'b c (h_n p1) (w_n p2) ->b h_n w_n (c p1 p2)', p1=1, p2=1)\n","        return self.net(x)\n","\n","\n","def create_mask(window_size, displacement, upper_lower, left_right):\n","    print('mask')\n","    mask =  mds.Tensor((window_size ** 2, window_size ** 2))\n","    print('mask')\n","    if upper_lower:\n","        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n","        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n","\n","    if left_right:\n","        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n","        mask[:, -displacement:, :, :-displacement] = float('-inf')\n","        mask[:, :-displacement, :, -displacement:] = float('-inf')\n","        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n","\n","    return mask\n","\n","\n","def get_relative_distances(window_size):\n","    indices = mds.Tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n","    distances = indices[None, :, :] - indices[:, None, :]\n","    return distances\n","\n","class PatchMerging(nn.Cell):\n","    def __init__(self, in_channels, out_channels=32, downscaling_factor=1):\n","        super().__init__()\n","        self.relu = nn.ReLU()\n","        self.conv1_1 = mds.ops.Conv2D(64, 3, pad_mode='same')\n","        self.conv2_1 = mds.ops.Conv2D(32, 3, pad_mode='same')\n","        self.conv3_1 = mds.ops.Conv2D(out_channels, 3, pad_mode='same')\n","        self.conv1_2 = mds.ops.Conv2D(64, 3, pad_mode='same')\n","        self.conv2_2 = mds.ops.Conv2D(32, 3, pad_mode='same')\n","        self.conv3_2 = mds.ops.Conv2D(out_channels, 3, pad_mode='same')\n","        self.conv1_3 = mds.ops.Conv2D(64, 3, pad_mode='same')\n","        self.conv2_3 = mds.ops.Conv2D(32, 3, pad_mode='same')\n","        self.conv3_3 = mds.ops.Conv2D(out_channels, 3, pad_mode='same')\n","        self.weight11 = mds.Tensor(np.ones([64, in_channels, 3, 3]), mds.float32)\n","        self.weight21 = mds.Tensor(np.ones([32, 64, 3, 3]), mds.float32)\n","        self.weight31 = mds.Tensor(np.ones([out_channels, 32, 3, 3]), mds.float32)\n","        self.weight12 = mds.Tensor(np.ones([64, in_channels, 3, 3]), mds.float32)\n","        self.weight22 = mds.Tensor(np.ones([32, 64, 3, 3]), mds.float32)\n","        self.weight32 = mds.Tensor(np.ones([out_channels, 32, 3, 3]), mds.float32)\n","        self.weight13 = mds.Tensor(np.ones([64, in_channels, 3, 3]), mds.float32)\n","        self.weight23 = mds.Tensor(np.ones([32, 64, 3, 3]), mds.float32)\n","        self.weight33 = mds.Tensor(np.ones([out_channels, 32, 3, 3]), mds.float32)\n","        self.patch_merge = nn.Unfold(ksizes=[1, downscaling_factor, downscaling_factor, 1], strides=[1,downscaling_factor, downscaling_factor, 1], rates=[1, downscaling_factor, downscaling_factor, 1])\n","#         self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n","        \n","        self.downscaling_factor = downscaling_factor\n","    def construct(self, x):\n","        b, c, h, w = x.shape\n","        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n","        x1 = self.conv3_1(self.relu(self.conv2_1(self.relu(self.conv1_1(x,self.weight11)),self.weight21)),self.weight31)\n","        x2 = self.conv3_2(self.relu(self.conv2_2(self.relu(self.conv1_2(x,self.weight12)),self.weight22)),self.weight32)\n","        x3 = self.conv3_3(self.relu(self.conv2_3(self.relu(self.conv1_3(x,self.weight13)),self.weight23)),self.weight33)\n","        x = mds.ops.Concat(1)((x1,x2,x3))\n","        x = mds.ops.Transpose()(x, (0, 2, 3, 1))\n","        return x\n","\n","class WindowAttention(nn.Cell):\n","    def __init__(self, in_channels, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n","        super().__init__()\n","        inner_dim = head_dim * heads\n","        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=dim)\n","\n","        self.heads = heads\n","        self.scale = head_dim ** -0.5\n","        self.window_size = window_size\n","        self.relative_pos_embedding = relative_pos_embedding\n","        self.shifted = shifted\n","\n","        if self.shifted:\n","            displacement = window_size // 2\n","            self.cyclic_shift = CyclicShift(-displacement)\n","            self.cyclic_back_shift = CyclicShift(displacement)\n","            self.upper_lower_mask = nn.ParameterUpdate(create_mask(window_size=window_size, displacement=displacement,\n","                                                             upper_lower=True, left_right=False), requires_grad=False)\n","            self.left_right_mask = nn.ParameterUpdate(create_mask(window_size=window_size, displacement=displacement,\n","                                                            upper_lower=False, left_right=True), requires_grad=False)\n","\n","        #self.to_qkv = nn.Dense(dim, inner_dim * 3, bias=False)\n","\n","        if self.relative_pos_embedding:\n","            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n","            self.pos_embedding = mds.ops.StandardNormal(2 * window_size - 1, 2 * window_size - 1)\n","        else:\n","            self.pos_embedding = mds.ops.StandardNormal(window_size ** 2, window_size ** 2)\n","\n","        self.to_out = nn.Dense(inner_dim, dim)\n","\n","    def construct(self, x):\n","        #经过cnn，得到qkv\n","        x = self.patch_partition(x)\n","        if self.shifted:\n","            x = self.cyclic_shift(x)\n","        b, n_h, n_w, ss, h = *x.shape, self.heads\n","        qkv = [x[:,:,:,:ss//3].asnumpy(), x[:,:,:,ss//3:ss//3*2].asnumpy(), x[:,:,:,ss//3*2:].asnumpy()]\n","#         qkv = x.chunk(3, dim=-1)\n","        nw_h = n_h // self.window_size\n","        nw_w = n_w // self.window_size\n","        q, k, v = map(\n","            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n","                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n","\n","        dots = np.einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n","        q = mds.Tensor(q)\n","        k = mds.Tensor(k)\n","        v = mds.Tensor(v)\n","#         if self.relative_pos_embedding:\n","#             dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n","#         else:\n","#             dots += self.pos_embedding\n","\n","#         if self.shifted:\n","#             dots[:, :, -nw_w:] += self.upper_lower_mask\n","#             dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n","        dots = mds.Tensor(dots)\n","#         attn = dots.softmax(dim=-1)\n","        attn = mds.ops.Softmax()(dots)\n","        out = np.einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n","        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n","                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n","        out = self.to_out(out)\n","\n","        if self.shifted:\n","            out = self.cyclic_back_shift(out)\n","\n","\n","        return out\n","\n","\n","\n","class SwinBlock(nn.Cell):\n","    def __init__(self, in_channels, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n","        super().__init__()\n","        self.attention_block = Residual(PreNorm(dim, WindowAttention(in_channels=in_channels,\n","                                                                     dim=dim,\n","                                                                     heads=heads,\n","                                                                     head_dim=head_dim,\n","                                                                     shifted=shifted,\n","                                                                     window_size=window_size,\n","                                                                     relative_pos_embedding=relative_pos_embedding)))\n","        #self.mlp_block = Residual(PreNorm(dim, Feedconstruct(dim=dim, hidden_dim=mlp_dim)))\n","\n","    def construct(self, x):\n","        #print('before swinblock:',x.shape)\n","        x = self.attention_block(x)\n","        #print(\"after_attrntion:\",x.shape)\n","        #x = self.mlp_block(x)\n","        #print(\"after_swin:\", x.shape)\n","        return x\n","\n","\n","\n","\n","\n","class StageCell(nn.Cell):\n","    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n","                 relative_pos_embedding):\n","        super().__init__()\n","        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted block.'\n","        self.downscaling_factor = downscaling_factor\n","        self.layers = nn.CellList([])\n","        for _ in range(layers // 2):\n","            self.layers.append(nn.CellList([\n","                SwinBlock(in_channels=in_channels,dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n","                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n","                SwinBlock(in_channels=in_channels,dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n","                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n","            ]))\n","\n","    def construct(self, x):\n","        for regular_block, shifted_block in self.layers:\n","            x = regular_block(x)\n","            x = shifted_block(x)\n","        return x\n","class merage(nn.Cell):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = mds.ops.Conv2D(out_channels, 3, pad_mode='same')\n","        self.relu = nn.ReLU()\n","    def construct(self, x, y):\n","        x = mds.ops.Concat(1)(x, y)\n","        #x = torch.add(x, y).permute(0, 2, 3, 1)\n","\n","        x = self.relu(self.conv(x))\n","        return x\n","\n","class ResBlock(nn.Cell):\n","\n","    def __init__(self, channels):\n","        super(ResBlock, self).__init__()\n","        self.conv1 = mds.ops.Conv2D(channels, 5, pad_mode='same')\n","        self.weight1 = mds.Tensor(np.ones([channels, 64, 5, 5]), mds.float32)\n","        # self.bn1 = nn.BatchNorm2d(channels)\n","        self.relu = nn.ReLU()\n","        self.conv2 = mds.ops.Conv2D(channels, 5, pad_mode='same')\n","        self.weight2 = mds.Tensor(np.ones([channels, channels, 5, 5]), mds.float32)\n","        # self.bn2 = nn.BatchNorm2d(channels)\n","\n","    def construct(self, x):\n","        residual = x\n","\n","        out = self.conv1(x,self.weight1)\n","        # out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out,self.weight2)\n","        # out = self.bn2(out)\n","\n","        out += residual\n","        # out = self.relu(out)\n","\n","        return out\n","\n","class Head(nn.Cell):\n","    \"\"\" Head consisting of convolution layers\n","    Extract features from corrupted images, mapping N3HW images into NCHW feature map.\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels=64, channels=32):\n","        super(Head, self).__init__()\n","        self.weight = mds.Tensor(np.ones([out_channels, 3, 3, 3]), mds.float32)\n","        self.conv1 = mds.ops.Conv2D(out_channels, 3, pad_mode='same')\n","        # self.bn1 = nn.BatchNorm2d(out_channels) if task_id in [0, 1, 5] else nn.Identity()\n","        # self.relu = nn.ReLU()\n","        self.resblock1 = ResBlock(out_channels)\n","        self.resblock2 = ResBlock(out_channels)\n","        self.conv2 = mds.ops.Conv2D(channels, 1, pad_mode='same')\n","        self.weight2 = mds.Tensor(np.ones([channels, out_channels, 1, 1]), mds.float32)\n","\n","    def construct(self, x):\n","        out = self.conv1(x, self.weight)\n","        # out = self.bn1(out)\n","        # out = self.relu(out)\n","\n","        out = self.resblock1(out)\n","        out = self.resblock2(out)\n","        out = self.conv2(out,self.weight2)\n","        return out\n","\n","class CURTransformer(nn.Cell):\n","    def __init__(self, *, hidden_dim, layers, heads, channels=32, num_classes=1000, head_dim=8, window_size=28,\n","                 downscaling_factors=1, relative_pos_embedding=False,scale_factor=0):\n","        super().__init__()\n","        self.sr = scale_factor\n","        self.stage1 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.stage2 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.stage3 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.stage4 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","\n","        self.merage1 = merage(in_channels=channels * 2, out_channels=channels)\n","        self.merage2 = merage(in_channels=channels * 2, out_channels=channels)\n","        self.merage3 = merage(in_channels=channels * 2, out_channels=channels)\n","        self.up_stage1 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.up_stage2 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.up_stage3 = StageCell(in_channels=channels, hidden_dimension=hidden_dim, layers=2,\n","                                  downscaling_factor=downscaling_factors, num_heads=heads, head_dim=head_dim,\n","                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n","        self.headsets = Head(3, 64, channels)\n","        self.tailsets = mds.ops.Conv2D(16, 3, pad_mode='same')\n","        #self.mlp_head = nn.Dense(96, 48)\n","\n","        # up-sampling\n","        #assert 2 <= scale_factor <= 4\n","        # if scale_factor == 2 or scale_factor == 4:\n","        #     self.upscale = []\n","        #     for _ in range(scale_factor // 2):\n","        #         self.upscale.extend([mds.ops.Conv2D(hidden_dim,hidden_dim* (2 ** 2), kernel_size=3, padding=1),\n","        #                              nn.PixelShuffle(2)])\n","        #     self.upscale = nn.Sequential(*self.upscale)\n","        # elif scale_factor == 3 :\n","        #     self.upscale = nn.Sequential(\n","        #         mds.ops.Conv2D(hidden_dim, hidden_dim * (scale_factor ** 2), kernel_size=3, padding=1),\n","        #         nn.PixelShuffle(scale_factor)\n","        #     )\n","\n","        self.conv2 = mds.ops.Conv2D(3, 3, pad_mode='same')\n","\n","    def construct(self, img):\n","        return img\n","        #b 3 hw->b 16 hw\n","        record = img\n","        x = self.headsets(img)\n","        #print(x.shape)\n","        x1 = self.stage1(x)\n","        x2 = self.stage2(x1)\n","        x3 = self.stage3(x2)\n","        x4 = self.stage4(x3)\n","        #print(x1.shape, x2.shape, x3.shape, x4.shape, x.shape)\n","        x = self.merage1(x4, x3)\n","        #print(x.shape)\n","        x = self.up_stage1(x)\n","        #print(x.shape)\n","        #print(x.shape)\n","        x = self.merage2(x, x2)\n","        #print(x.shape)\n","        x = self.up_stage2(x)\n","        #print(x.shape)\n","        x = self.merage3(x, x1)\n","\n","        x = self.up_stage3(x)\n","        # if self.sr != 0:\n","        #     x = self.upscale(x)\n","        x = self.conv2(x)\n","        return x+img\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["from mindspore import Model\n","from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[('./data/rgb/6.png', './data/noise/6.png'), ('./data/rgb/3.png', './data/noise/3.png')] 7\n","1\n","2\n","3\n","(1, 3, 224, 224)\n"]}],"source":["###加载数据  设置batchsize\n","# yern\n","#print(tra)\n","tra,val=load_data_path(left_path,right_path,split_ratio)\n","print(tra[:2],len(tra))\n","dataset=imgDataset(tra)\n","#traindataset=ds.GeneratorDataset(data_generator(tra),column_names=['img','label'],num_parallel_workers=4)\n","traindataset=ds.GeneratorDataset(dataset,column_names=['img','label'],num_parallel_workers=4)\n","print(1)\n","traindataset=traindataset.batch(1)\n","print(2)\n","NET=CURTransformer(\n","        hidden_dim=32,\n","        layers=(2, 2, 6, 2),\n","        heads=1,\n","        channels=32,\n","        num_classes=3,\n","        head_dim=32,\n","        window_size=14,\n","        downscaling_factors=1,\n","        relative_pos_embedding=False\n","    )\n","print(3)\n","input_x = mds.Tensor(np.ones([1, 3, 224, 224]), mds.float32)\n","print(NET(input_x).shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["OK\n"]}],"source":["\n","import mindspore.nn as nn\n","import numpy as np\n","from mindspore.nn import Loss\n","import mindspore.ops as ops\n","import mindspore as ms\n","from mindspore import Tensor\n","class MISS_1(nn.Cell):\n","    def __init__(self):\n","        super(MISS_1,self).__init__()\n","        self.lossfn=nn.SSIM()\n","    def construct(self,data,label):\n","        ssim=self.lossfn(data,label)\n","        ones=mdsnp.full_like(ssim,1)\n","        return ones-ssim\n","class SLoss(nn.Cell):\n","    def __init__(self, base_num_filter=8):\n","        super(SLoss, self).__init__()\n","        self.exp = ops.Exp()\n","#         self.conv2d = nn.Conv2d(in_channels = 1, out_channels = 3, kernel_size = 3)\n","\n","    def construct(self, pred, true):\n","        loss = self.getloss(pred, true)\n","        return loss\n","\n","    def getloss(self, pred, true):\n","        \n","        y_true = true[:, 0:6, 10:-10, 10:-10]\n","        y_pred = pred[:, 0:6, 10:-10, 10:-10]\n","        y_true_V = y_true[:, 0:1, :, :]\n","        y_true_U = y_true[:, 1:2, :, :]\n","        y_true_Y = y_true[:, 2:3, :, :]\n","        y_true_reverse_V = y_true[:, 3:4, :, :]\n","        y_true_reverse_U = y_true[:, 4:5, :, :]\n","        y_true_reverse_Y = y_true[:, 5:6, :, :]\n","\n","        y_pred_V = y_pred[:, 0:1, :, :]\n","        y_pred_U = y_pred[:, 1:2, :, :]\n","        y_pred_Y = y_pred[:, 2:3, :, :]\n","        y_pred_reverse_V = y_pred[:, 3:4, :, :]\n","        y_pred_reverse_U = y_pred[:, 4:5, :, :]\n","        y_pred_reverse_Y = y_pred[:, 5:6, :, :]\n","        \n","        #print(true)\n","        #print(y_pred)\n","        #ssim1=1\n","        ssim1 = self.tf_ssim011(y_pred_Y, y_true_Y, max_val=255.0)\n","        ssim2 = self.tf_ssim(y_pred_reverse_V, y_true_reverse_V, max_val=255.0)\n","        ssim3 = self.tf_ssim(y_pred_reverse_U, y_true_reverse_U, max_val=255.0)\n","\n","        ssim = (ssim1 + ssim2 + ssim3) / 3.0\n","        return 1 - ssim\n","\n","    def tf_ssim(self,img1, img2, max_val=1, cs_map=False, mean_metric=True):\n","        K1 = 0.01\n","        K2 = 0.03\n","        L = max_val  # depth of image (255 in case the image has a different scale)\n","        C1 = (K1 * L) ** 2\n","        C2 = (K2 * L) ** 2\n","        mu1 = self.conv2d(img1)\n","        mu2 = self.conv2d(img2)\n","        mu1_sq = mu1 * mu1\n","        mu2_sq = mu2 * mu2\n","        mu1_mu2 = mu1 * mu2\n","\n","        sigma1_sq = self.conv2d(img1 * img1) - mu1_sq\n","        sigma2_sq = self.conv2d(img2 * img2) - mu2_sq\n","        sigma12 = self.conv2d(img1 * img2) - mu1_mu2\n","        if cs_map:\n","            value = (((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n","                                                                  (sigma1_sq + sigma2_sq + C2)),\n","                     (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2))\n","        else:\n","            value = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n","                                                                 (sigma1_sq + sigma2_sq + C2))\n","        reducemean = ops.ReduceMean()\n","        if mean_metric:\n","            value = reducemean(value)\n","        return value\n","    \n","    def tf_ssim011(self, img1, img2, max_val=1, mean_metric=True):\n","        K1 = 0.01\n","        K2 = 0.03\n","        L = max_val  # depth of image (255 in case the image has a different scale)\n","        C1 = (K1 * L) ** 2\n","        C2 = (K2 * L) ** 2\n","        #print(img1)\n","        mu1 = self.conv2d(img1)\n","        mu2 = self.conv2d(img2)\n","        mu1_sq = mu1 * mu1\n","        mu2_sq = mu2 * mu2\n","        mu1_mu2 = mu1 * mu2\n","\n","        sigma1_sq = self.conv2d(img1 * img1) - mu1_sq\n","        sigma2_sq = self.conv2d(img2 * img2) - mu2_sq\n","        sigma12 = self.conv2d(img1 * img2) - mu1_mu2\n","        value = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n","        if mean_metric:\n","            value = value.mean()\n","        return value\n","    \n","testloss = SLoss()\n","print(\"OK\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["###training \n","#Loss=MISS_1()\n","Loss2=SLoss()\n","trainDataset=imgDataset(tra)\n","trainData=ds.GeneratorDataset(trainDataset,column_names=['img','label'],num_parallel_workers=1)\n","trainData=trainData.batch(1)\n","\n","optim=nn.RMSProp(params=NET.trainable_params(), learning_rate=0.001)\n","trainnet=Model(NET,loss_fn=Loss2,optimizer=optim)\n","loss_cb = LossMonitor(per_print_times=1)\n","ckpt_config = CheckpointConfig(save_checkpoint_steps=1, keep_checkpoint_max=1)\n","ckpoint_cb = ModelCheckpoint(prefix='coloring', directory='./model', config=ckpt_config)\n","print('start    training')\n","trainnet.train(8,trainData)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"ename":"ValueError","evalue":"The checkpoint file does not exist.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-698c4816ba0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_param_into_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mckpt_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model/coloring_2-8_775.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparam_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m net=CURTransformer(\n\u001b[1;32m      6\u001b[0m         \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/train/serialization.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(ckpt_file_name, net, strict_load, filter_prefix, dec_key, dec_mode)\u001b[0m\n\u001b[1;32m    399\u001b[0m         Parameter (name=conv2.weight, shape=(16, 6, 5, 5), dtype=Float32, requires_grad=True\n\u001b[1;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mckpt_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_checkpoint_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0mdec_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dec_key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mdec_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dec_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/train/serialization.py\u001b[0m in \u001b[0;36m_check_checkpoint_param\u001b[0;34m(ckpt_file_name, filter_prefix)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The checkpoint file does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mckpt_file_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The checkpoint file does not exist."]}],"source":["#推理部分\n","from mindspore import load_checkpoint, load_param_into_net\n","ckpt_file_name = \"./model/coloring_2-8_775.ckpt\"\n","param_set = load_checkpoint(ckpt_file_name)\n","net=CURTransformer(\n","        hidden_dim=32,\n","        layers=(2, 2, 6, 2),\n","        heads=1,\n","        channels=32,\n","        num_classes=3,\n","        head_dim=32,\n","        window_size=14,\n","        downscaling_factors=1,\n","        relative_pos_embedding=True\n","    )\n","load_param_into_net(net, param_set)\n","Loss3=SLoss()\n","optim=nn.RMSProp(params=NET.trainable_params(), learning_rate=0.001)\n","model=Model(net,loss_fn=Loss3,optimizer=optim)\n","\n","testDataset=imgDataset(val)\n","testdataset=ds.GeneratorDataset(testDataset,column_names=['img','label'],num_parallel_workers=4)\n","testdataset=testdataset.batch(1)\n","\n","testdata_iter = testdataset.create_dict_iterator()\n","testdata = next(testdata_iter)\n","#print(Tensor(testdata['img']).shape)\n","predicted = model.predict(Tensor(testdata['img']))\n","predicted=predicted[0]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.0rc2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"d535a121a8bc211d040337c8a29b58604b2f850073de06d14bf123a7972ece68"}}},"nbformat":4,"nbformat_minor":5}
